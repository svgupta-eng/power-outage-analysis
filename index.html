<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Power Outage Project</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            max-width: 800px;
            margin: 40px auto;
            padding: 0 20px;
            color: #333;
        }

        /* MAIN TITLE (The biggest text on the page) */
        .main-header {
            text-align: center;
            margin-bottom: 60px;
            border-bottom: 2px solid #eee;
            padding-bottom: 20px;
        }
        .main-header h1 {
            font-size: 36px;
            margin-bottom: 10px;
            color: #2c3e50;
        }
        .creators {
            font-size: 18px;
            color: #666;
            font-style: italic;
        }

        /* SECTION HEADERS (Introduction, Data Cleaning - these will match!) */
        h2 {
            font-size: 24px;  /* Explicitly sets the size for ALL h2 tags */
            color: #2c3e50;
            margin-top: 40px;
            border-left: 5px solid #3498db;
            padding-left: 15px;
        }

        code {
            background-color: #f4f4f4;
            padding: 2px 5px;
            border-radius: 4px;
            font-family: monospace;
        }
    </style>
</head>
<body>

    <div class="main-header">
        <h1>Power Outage Analysis</h1>
        <p class="creators">By Sana Gupta & Aarushi Jain</p> 
    </div>

    <h2>Introduction</h2>
    <p>
    Our dataset contains detailed information on power outages across different U.S. states, with each row 
    representing a single outage event. These events include when the outage began, how long it lasted, how many 
    customers were affected, and what factors contributed to the disruption. Understanding this dataset is important 
    because power outages are becoming increasingly common due to aging infrastructure, extreme weather, and rising 
    energy demands. By examining outage patterns, we can better understand which factors contribute most to 
    disruptions and potentially identify ways to reduce their impact on communities.
    </p>

    <p>
    The central question guiding this project is: <strong>Which factors are most strongly associated with longer 
    power outage durations?</strong> This question matters because outage duration directly affects public safety, 
    economic loss, and community resilience. If we can understand what drives long outages, decision-makers can 
    better prepare and respond to emergencies.
    </p>

    <p>The dataset contains <strong>1534 rows</strong>. The relevant columns for this question are:</p>

    <ul>
        <li><strong>OUTAGE.START</strong> — The start date and time of the outage event.</li>
        <li><strong>OUTAGE.DURATION</strong> — The length of the outage in minutes.</li>
        <li><strong>CUSTOMERS.AFFECTED</strong> — Estimated number of customers impacted.</li>
        <li><strong>CAUSE.CATEGORY</strong> — High-level category describing the primary cause of the outage.</li>
        <li><strong>CAUSE.SUBCATEGORY</strong> — More specific details about the cause.</li>
        <li><strong>CLIMATE.REGION</strong> — The assigned climate region for the state in which the outage occurred.</li>
    </ul>

    <p>
    These initial observations help motivate deeper analysis into which factors are truly connected to longer 
    outage durations.
    </p>


    <h2>Data Cleaning and Exploratory Data Analysis</h2>
    <p>
    Before analyzing the dataset, several cleaning steps were necessary to ensure accuracy and consistency. First, 
    rows containing header information and unrelated metadata were removed so the dataset included only valid 
    outage records. Placeholder values such as <code>--</code>, <code>Unknown</code>, and <code>N/A</code> were replaced with proper 
    missing values to prevent incorrect interpretation during analysis. Numeric columns such as <code>YEAR</code>, 
    <code>MONTH</code>, <code>POPULATION</code>, and <code>OUTAGE.DURATION</code> were converted to numeric types, with invalid values coerced 
    to missing where appropriate.
    </p>

    <p>
    Next, the outage start date and time were combined into a single <code>OUTAGE.START</code> column to reflect the full 
    timestamp of each event. Redundant columns such as <code>OUTAGE.START.DATE</code> and <code>OUTAGE.START.TIME</code> were then 
    removed. Additionally, an <code>URBANIZATION</code> variable was created by combining <code>POPPCT_URBAN</code> and 
    <code>POPPCT_UC</code> to give a more comprehensive understanding of the urban population share in each state.
    </p>

    <p>
    These data cleaning steps ensured the dataset was well-structured and ready for exploratory analysis. Below, we 
    present both univariate and bivariate visualizations, as well as grouped summaries, to explore how various 
    factors relate to outage duration and outage characteristics across states and causes.
    </p>

    <h3>1. Outages by Month</h3>
    <iframe src="assets/outages_by_month.html" width="100%" height="600" frameborder="0"></iframe>
    <p>
    This bar chart shows how outages are distributed across the year, with clear peaks in summer months like June and July, when heat and higher energy demand put extra stress on the grid.
    </p>

    <h3>2. Outages by Climate Region</h3>
    <iframe src="assets/outages_by_climate_region.html" width="100%" height="600" frameborder="0"></iframe>
    <p>
    This plot compares outage frequency across climate regions and shows that the Northeast and some southern and western regions experience more outages, reflecting differences in weather patterns and infrastructure.
    </p>

    <h3>3. Population by Outage Cause</h3>
    <iframe src="assets/population_by_cause.html" width="100%" height="600" frameborder="0"></iframe>
    <p>
    This boxplot shows that outages from system operability issues and fuel supply emergencies tend to affect states with larger populations, while causes like intentional attacks and severe weather skew toward smaller or less urban states.
    </p>

<h2>Assessment of Missingness</h2>
    <p>
    We believe that the <strong>CUSTOMERS.AFFECTED</strong> column is likely <strong>NMAR</strong> (Not Missing At Random). 
    </p>

    <p>
    <strong>Reasoning:</strong> The missingness in this column is likely dependent on the missing value itself. 
    Utility companies and federal agencies are more rigorous about recording data for massive, high-impact events. 
    If an outage affects a very small number of people, it may not trigger the reporting threshold required by 
    department of energy guidelines, or the utility might simply prioritize restoring power over precise clerical documentation 
    for minor events. Therefore, the probability of the value being missing increases as the actual number of customers affected decreases. 
    Because the missingness depends on the value of the data we typically cannot see, this falls under NMAR.
    </p>

    <p>
    <strong>Additional Data:</strong> To transform this from NMAR to MAR (Missing At Random), we would want to obtain 
    data regarding the <strong>reporting policies and minimum thresholds</strong> of the specific utility companies involved. 
    If we had a dataset showing that "Utility Company X only reports outages affecting >500 customers," we could explain 
    the missingness using that observed variable.
    </p>

<p>
    <strong>Additional Data:</strong> To transform this from NMAR to MAR (Missing At Random), we would want to obtain 
    data regarding the <strong>reporting policies and minimum thresholds</strong> of the specific utility companies involved.
    </p>

    <h3>Missingness Plot</h3>
    <p>The plot below visualizes the distribution of missing values in our dataset.</p>
    <iframe src="assets/missingness_plot.html" width="100%" height="600" frameborder="0"></iframe>

<h2>Hypothesis Testing</h2>
    <p>
    To understand if the timing of outages correlates with their severity, we performed a permutation test 
    to analyze the relationship between the month of the outage and its duration.
    </p>

    <p><strong>Null Hypothesis:</strong> The average outage duration is the same for outages occurring in odd-numbered months 
    and even-numbered months. Any observed difference is due to random chance.</p>

    <p><strong>Alternative Hypothesis:</strong> The average outage duration differs between odd-month and even-month outages.</p>

    <p>
    <strong>Test Statistic:</strong> The difference in mean outage duration between the two groups (Mean of Odd Months - Mean of Even Months).
    We chose this statistic because it is a direct measure of the magnitude of difference between the two distributions.
    </p>

    <p>
    <strong>Significance Level:</strong> 0.05
    </p>

    <p>
    <strong>Resulting P-value:</strong> 0.318
    </p>

    <p>
    <strong>Conclusion:</strong> 
    Since the p-value (0.318) is greater than the significance level (0.05), we <strong>fail to reject the null hypothesis</strong>. 
    This suggests that the "parity" of the month (whether it is odd or even) does not have a statistically significant 
    association with the duration of power outages. This result is consistent with our intuition, as month parity is an 
    arbitrary calendar feature rather than a physical or environmental factor likely to influence power grid stability.
    </p>


<h2>Framing a Prediction Problem</h2>
    <p>
    <strong>Problem Statement:</strong> 
    The goal of our machine learning model is to predict the <strong>CAUSE.CATEGORY</strong> of a power outage based on 
    characteristics available at the start of the event.
    </p>

    <p>
    <strong>Type of Problem:</strong> 
    This is a <strong>multiclass classification</strong> problem because <code>CAUSE.CATEGORY</code> is a nominal variable 
    with several distinct classes (e.g., "severe weather", "equipment failure", "intentional attack").
    </p>

    <p>
    <strong>Response Variable:</strong> 
    We chose <code>CAUSE.CATEGORY</code> as the response variable. Predicting the cause of an outage is crucial because it allows 
    utility companies to better allocate specific resources (e.g., technicians vs. security personnel), respond faster, and 
    identify regions that are disproportionately vulnerable to specific types of outage drivers.
    </p>

    <p>
    <strong>Features Used:</strong> 
    To ensure a realistic prediction model, we only used features that would be known <strong>at the time the outage begins</strong>. 
    These include:
    </p>
    <ul>
        <li><code>YEAR</code> and <code>MONTH</code> (Temporal context)</li>
        <li><code>CLIMATE.REGION</code> and <code>CLIMATE.CATEGORY</code> (Environmental context)</li>
        <li><code>POPULATION</code> and <code>URBANIZATION</code> (Demographic context)</li>
        <li><code>NERC.REGION</code> (Grid infrastructure context)</li>
    </ul>
    <p>
    We explicitly excluded variables like <code>OUTAGE.DURATION</code> and restoration time, as these metrics are only known 
    <em>after</em> the outage has been resolved.
    </p>

    <p>
    <strong>Evaluation Metric:</strong> 
    We are using <strong>Accuracy</strong> as our primary evaluation metric. Since this is a baseline multiclass classifier, 
    accuracy provides a straightforward measure of how often the model correctly identifies the cause. 
    (Note: If we find significant class imbalance later, we may consider F1-score).
    </p>

<h2>Baseline Model</h2>
    <p>
    For our baseline model, we chose a <strong>Logistic Regression</strong> classifier to predict the cause of the power outage. 
    We split the data into 80% training and 20% testing sets.
    </p>

    <p><strong>Features Used:</strong></p>
    <ul>
        <li><strong>Quantitative Features (2):</strong> <code>YEAR</code> and <code>URBANIZATION</code>. 
        These were passed through the model directly ("passthrough") without scaling.</li>
        
        <li><strong>Nominal Features (1):</strong> <code>CLIMATE.REGION</code>. 
        Since this is a categorical variable with no inherent order, we performed <strong>One-Hot Encoding</strong> 
        to convert the regions into binary vectors (0s and 1s).</li>
        
        <li><strong>Ordinal Features:</strong> None used in this baseline.</li>
    </ul>

    <p><strong>Performance:</strong></p>
    <p>
    The model achieved an <strong>Accuracy of 47.2%</strong> (0.4723).
    </p>

    <p><strong>Evaluation:</strong></p>
    <p>
    We consider this current model to be <strong>a reasonable start, but not "good" yet</strong>. 
    While an accuracy of 47% is significantly better than random guessing (which would be around 14% given there are 7 potential categories), 
    the model still incorrectly predicts the cause of the outage more than half the time. This suggests that just knowing the location (Climate Region) 
    and urbanization level isn't enough to distinguish between complex causes like "equipment failure" versus "severe weather." 
    We likely need more specific features, such as weather data or grid characteristics, to improve performance.
    </p>

<h2>Final Model</h2>
    
    <h3>Feature Engineering</h3>
    <p>
    To improve upon the baseline, we added four new features: <code>MONTH</code>, <code>CLIMATE.CATEGORY</code>, 
    <code>POPULATION</code>, and <code>NERC.REGION</code>. We believe these features are critical from a "data generating" perspective:
    </p>
    <ul>
        <li><strong>MONTH:</strong> Power outages are highly seasonal. "Severe Weather" causes (like snowstorms vs. hurricanes vs. heatwaves) 
        happen at specific times of the year. By including the month, the model can differentiate between a winter outage (likely ice/snow) 
        and a summer outage (likely heat/overload).</li>
        <li><strong>CLIMATE.CATEGORY:</strong> While <code>CLIMATE.REGION</code> tells us "where", <code>CLIMATE.CATEGORY</code> 
        (e.g., "Cold", "Warm", "Normal") explicitly flags extreme environmental conditions. Outages during "Cold" periods are mechanically different 
        (frozen lines) than those during "Normal" periods.</li>
        <li><strong>NERC.REGION:</strong> The North American grid is divided into regional interconnects (like WECC, TRE, MRO) which have 
        different infrastructure standards and reporting protocols. An outage in the Texas (TRE) grid often has different characteristic causes 
        compared to the Northeast.</li>
        <li><strong>POPULATION:</strong> Higher population density correlates with more complex grid infrastructure and higher demand. 
        Equipment failures might be more common in older, densely populated cities compared to rural areas where lines are exposed to nature.</li>
    </ul>

    <h3>Modeling Algorithm</h3>
    <p>
    We chose a <strong>Random Forest Classifier</strong> for our final model. Random Forests are excellent for this type of data because 
    they can capture non-linear relationships (e.g., the interaction between "Month=January" and "Region=Northeast") and are generally 
    more robust to overfitting than a single Decision Tree.
    </p>

    <h3>Hyperparameter Tuning</h3>
    <p>
    We used <code>GridSearchCV</code> with 5-fold cross-validation to find the optimal hyperparameters. We searched over the following range:
    </p>
    <ul>
        <li><code>n_estimators</code>: [200, 300] (Number of trees)</li>
        <li><code>max_depth</code>: [None, 15, 25] (Maximum depth of each tree)</li>
        <li><code>min_samples_leaf</code>: [1, 3] (Minimum samples required at a leaf node)</li>
    </ul>
    <p>
    <strong>Best Hyperparameters:</strong> The best performing model used <code>n_estimators=300</code>, 
    <code>max_depth=None</code>, and <code>min_samples_leaf=3</code>.
    </p>

    <h3>Performance Improvement</h3>
    <p>
    Our Final Model achieved an accuracy of <strong>69.1%</strong>, which is a substantial improvement over the Baseline Model's 
    accuracy of 47.2%. 
    </p>
    <p>
    The increase of approximately <strong>22 percentage points</strong> demonstrates that the added features (especially <code>MONTH</code> 
    and <code>NERC.REGION</code>) provided crucial signal that the location alone could not capture. By understanding the "when" (Month) 
    and the specific grid infrastructure (NERC), the Random Forest was able to better distinguish between causes like "Severe Weather" 
    and "System Operability Disruption."
    </p>

<h2>Fairness Analysis</h2>
    <p>
    We evaluated whether our model is fair across different geographical landscapes. Specifically, we assessed if the model performs 
    equally well for highly urbanized states versus less urbanized (more rural) states.
    </p>

    <p><strong>Groups Analyzed:</strong></p>
    <ul>
        <li><strong>Group X (High Urbanization):</strong> States with an urbanization rate above or equal to the median.</li>
        <li><strong>Group Y (Low Urbanization):</strong> States with an urbanization rate below the median.</li>
    </ul>

    <p><strong>Evaluation Metric:</strong></p>
    <p>
    We used <strong>Accuracy</strong> as our parity measure. We calculated the difference in prediction accuracy between 
    the high-urbanization and low-urbanization groups.
    </p>

    <p><strong>Hypotheses:</strong></p>
    <ul>
        <li><strong>Null Hypothesis ($H_0$):</strong> Our model is fair. Its accuracy for high-urbanization states and low-urbanization states is roughly the same, and any observed difference is due to random chance.</li>
        <li><strong>Alternative Hypothesis ($H_1$):</strong> Our model is unfair. Its accuracy for high-urbanization states is significantly different from its accuracy for low-urbanization states.</li>
    </ul>

    <p><strong>Test Statistic:</strong> Difference in accuracy (Accuracy of High Urban - Accuracy of Low Urban).</p>
    <p><strong>Significance Level:</strong> 0.05</p>

    <p><strong>Results:</strong></p>
    <p>
    After performing a permutation test with 1,000 permutations, we obtained the following results:
    </p>
    <ul>
        <li><strong>Observed Accuracy Difference:</strong> INSERT_OBSERVED_DIFF_HERE (e.g., 0.04)</li>
        <li><strong>P-value:</strong> INSERT_P_VALUE_HERE (e.g., 0.28)</li>
    </ul>

    <p><strong>Conclusion:</strong></p>
    <p>
    Since the p-value is greater than 0.05, we <strong>fail to reject the null hypothesis</strong>. 
    This suggests that our model does not suffer from significant bias based on urbanization; it predicts outage causes 
    with roughly equal reliability for both rural and urban states.
    
    </p>


</body>
</html>

</body>
</html>
